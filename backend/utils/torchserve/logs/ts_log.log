2025-05-05T19:40:07,154 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-05-05T19:40:07,154 [WARN ] main org.pytorch.serve.util.ConfigManager - Your torchserve instance can access any URL to load models. When deploying to production, make sure to limit the set of allowed_urls in config.properties
2025-05-05T19:40:07,173 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-05-05T19:40:07,173 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager - Initializing plugins manager...
2025-05-05T19:40:07,202 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml
2025-05-05T19:40:07,202 [INFO ] main org.pytorch.serve.metrics.configuration.MetricConfiguration - Successfully loaded metrics configuration from /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml
2025-05-05T19:40:07,233 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages
Current directory: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve
Temp directory: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/
Metrics config path: /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 6144 M
Python executable: /Users/bohan/miniconda3/envs/animated_drawings/bin/python
Config file: config.local.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/model-store
Initial Models: all
Log dir: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/logs
Metrics dir: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/model-store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: false
2025-05-05T19:40:07,233 [INFO ] main org.pytorch.serve.ModelServer - 
Torchserve version: 0.12.0
TS Home: /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages
Current directory: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve
Temp directory: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/
Metrics config path: /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml
Number of GPUs: 0
Number of CPUs: 8
Max heap size: 6144 M
Python executable: /Users/bohan/miniconda3/envs/animated_drawings/bin/python
Config file: config.local.properties
Inference address: http://0.0.0.0:8080
Management address: http://0.0.0.0:8081
Metrics address: http://0.0.0.0:8082
Model Store: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/model-store
Initial Models: all
Log dir: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/logs
Metrics dir: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/logs
Netty threads: 0
Netty client threads: 0
Default workers per model: 8
Blacklist Regex: N/A
Maximum Response Size: 6553500
Maximum Request Size: 6553500
Limit Maximum Image Pixels: true
Prefer direct buffer: false
Allowed Urls: [file://.*|http(s)?://.*]
Custom python dependency for model allowed: false
Enable metrics API: true
Metrics mode: LOG
Disable system metrics: false
Workflow Store: /Users/bohan/Downloads/AnimatedDrawings-main/torchserve/model-store
CPP log config: N/A
Model config: N/A
System metrics command: default
Model API enabled: false
2025-05-05T19:40:07,238 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-05-05T19:40:07,238 [INFO ] main org.pytorch.serve.servingsdk.impl.PluginsManager -  Loading snapshot serializer plugin...
2025-05-05T19:40:07,246 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: drawn_humanoid_pose_estimator.mar
2025-05-05T19:40:07,246 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: drawn_humanoid_pose_estimator.mar
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model drawn_humanoid_pose_estimator
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model drawn_humanoid_pose_estimator
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model drawn_humanoid_pose_estimator
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model drawn_humanoid_pose_estimator
2025-05-05T19:40:10,503 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model drawn_humanoid_pose_estimator loaded.
2025-05-05T19:40:10,503 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model drawn_humanoid_pose_estimator loaded.
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: drawn_humanoid_pose_estimator, count: 8
2025-05-05T19:40:10,503 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: drawn_humanoid_pose_estimator, count: 8
2025-05-05T19:40:10,507 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: drawn_humanoid_detector.mar
2025-05-05T19:40:10,507 [DEBUG] main org.pytorch.serve.ModelServer - Loading models from model store: drawn_humanoid_detector.mar
2025-05-05T19:40:10,507 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9004, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9003, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9005, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9006, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9002, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9007, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,508 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9001, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:10,507 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9000, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:11,681 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9004
2025-05-05T19:40:11,686 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,686 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]34999
2025-05-05T19:40:11,686 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,686 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,687 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,687 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,701 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-05-05T19:40:11,701 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9004
2025-05-05T19:40:11,759 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9004).
2025-05-05T19:40:11,763 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211763
2025-05-05T19:40:11,763 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211763
2025-05-05T19:40:11,765 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211765
2025-05-05T19:40:11,765 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211765
2025-05-05T19:40:11,781 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,891 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9005
2025-05-05T19:40:11,895 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,895 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35001
2025-05-05T19:40:11,895 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,895 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,895 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,896 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,896 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-05-05T19:40:11,896 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9005
2025-05-05T19:40:11,897 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211897
2025-05-05T19:40:11,897 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211897
2025-05-05T19:40:11,897 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9005).
2025-05-05T19:40:11,897 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211897
2025-05-05T19:40:11,897 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211897
2025-05-05T19:40:11,903 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,903 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9003
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35000
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,908 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,908 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-05-05T19:40:11,908 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9003
2025-05-05T19:40:11,910 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9003).
2025-05-05T19:40:11,910 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211910
2025-05-05T19:40:11,910 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211910
2025-05-05T19:40:11,910 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211910
2025-05-05T19:40:11,910 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211910
2025-05-05T19:40:11,916 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,916 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9001
2025-05-05T19:40:11,920 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9002
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,921 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9006
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35005
2025-05-05T19:40:11,922 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,922 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9001
2025-05-05T19:40:11,924 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211924
2025-05-05T19:40:11,924 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9001).
2025-05-05T19:40:11,924 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211924
2025-05-05T19:40:11,924 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211924
2025-05-05T19:40:11,924 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211924
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35003
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,924 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,924 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-05-05T19:40:11,924 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9002
2025-05-05T19:40:11,927 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,927 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35002
2025-05-05T19:40:11,927 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9002).
2025-05-05T19:40:11,928 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,928 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,928 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,928 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211928
2025-05-05T19:40:11,928 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211928
2025-05-05T19:40:11,928 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,928 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211928
2025-05-05T19:40:11,928 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2025-05-05T19:40:11,928 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211928
2025-05-05T19:40:11,928 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9006
2025-05-05T19:40:11,929 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,930 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9006).
2025-05-05T19:40:11,930 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211930
2025-05-05T19:40:11,930 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211930
2025-05-05T19:40:11,930 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211930
2025-05-05T19:40:11,930 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211930
2025-05-05T19:40:11,937 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,945 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:11,972 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9007
2025-05-05T19:40:11,978 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:11,978 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35004
2025-05-05T19:40:11,979 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:11,979 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,979 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:11,979 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2025-05-05T19:40:11,979 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9007
2025-05-05T19:40:11,979 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:11,980 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9007).
2025-05-05T19:40:11,981 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211980
2025-05-05T19:40:11,981 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445211980
2025-05-05T19:40:11,981 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211981
2025-05-05T19:40:11,981 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445211981
2025-05-05T19:40:11,985 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:12,007 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9000
2025-05-05T19:40:12,014 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:12,015 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - [PID]35006
2025-05-05T19:40:12,015 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:12,015 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:12,015 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-drawn_humanoid_pose_estimator_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:12,015 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:12,015 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-05-05T19:40:12,015 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9000
2025-05-05T19:40:12,016 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9000).
2025-05-05T19:40:12,017 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445212017
2025-05-05T19:40:12,017 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445212017
2025-05-05T19:40:12,017 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445212017
2025-05-05T19:40:12,017 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445212017
2025-05-05T19:40:12,024 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_pose_estimator, batchSize: 1
2025-05-05T19:40:15,135 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,136 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,136 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,136 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,136 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,137 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,137 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,137 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,137 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,137 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,138 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,138 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,138 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,138 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,139 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,139 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,140 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,141 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,141 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,141 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,142 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,142 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,142 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,142 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,143 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,144 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,144 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,144 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:15,145 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,148 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:15,149 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:15,149 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:15,732 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model drawn_humanoid_detector
2025-05-05T19:40:15,732 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Adding new version 1.0 for model drawn_humanoid_detector
2025-05-05T19:40:15,733 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model drawn_humanoid_detector
2025-05-05T19:40:15,733 [DEBUG] main org.pytorch.serve.wlm.ModelVersionedRefs - Setting default version to 1.0 for model drawn_humanoid_detector
2025-05-05T19:40:15,733 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model drawn_humanoid_detector loaded.
2025-05-05T19:40:15,733 [INFO ] main org.pytorch.serve.wlm.ModelManager - Model drawn_humanoid_detector loaded.
2025-05-05T19:40:15,733 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: drawn_humanoid_detector, count: 8
2025-05-05T19:40:15,733 [DEBUG] main org.pytorch.serve.wlm.ModelManager - updateModel: drawn_humanoid_detector, count: 8
2025-05-05T19:40:15,734 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9008, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,734 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9008, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,734 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9009, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,734 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9009, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9010, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9012, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9010, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9011, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9013, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9011, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9012, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9014, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9013, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,735 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9014, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,736 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9015, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,736 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerLifeCycle - Worker cmdline: [/Users/bohan/miniconda3/envs/animated_drawings/bin/python, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/model_service_worker.py, --sock-type, tcp, --port, 9015, --metrics-config, /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml]
2025-05-05T19:40:15,736 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-05-05T19:40:15,736 [INFO ] main org.pytorch.serve.ModelServer - Initialize Inference server with: NioServerSocketChannel.
2025-05-05T19:40:15,776 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-05-05T19:40:15,776 [INFO ] main org.pytorch.serve.ModelServer - Inference API bind to: http://0.0.0.0:8080
2025-05-05T19:40:15,776 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-05-05T19:40:15,776 [INFO ] main org.pytorch.serve.ModelServer - Initialize Management server with: NioServerSocketChannel.
2025-05-05T19:40:15,781 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-05-05T19:40:15,781 [INFO ] main org.pytorch.serve.ModelServer - Management API bind to: http://0.0.0.0:8081
2025-05-05T19:40:15,784 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-05-05T19:40:15,784 [INFO ] main org.pytorch.serve.ModelServer - Initialize Metrics server with: NioServerSocketChannel.
2025-05-05T19:40:15,786 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-05-05T19:40:15,786 [INFO ] main org.pytorch.serve.ModelServer - Metrics API bind to: http://0.0.0.0:8082
2025-05-05T19:40:15,973 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-05-05T19:40:15,973 [WARN ] pool-3-thread-1 org.pytorch.serve.metrics.MetricCollector - worker pid is not available yet.
2025-05-05T19:40:16,209 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,215 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:69.8297119140625|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,219 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,219 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:17.6|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,219 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:4572.875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,228 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7355.609375|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:16,228 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:81.4|#Level:Host|#hostname:192.168.31.54,timestamp:1746445216
2025-05-05T19:40:17,248 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5324
2025-05-05T19:40:17,248 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5324
2025-05-05T19:40:17,249 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,249 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9001-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,250 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6744.0|#WorkerName:W-9001-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,251 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,310 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5293
2025-05-05T19:40:17,310 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5293
2025-05-05T19:40:17,310 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,310 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9000-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,310 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6805.0|#WorkerName:W-9000-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,311 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,488 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5723
2025-05-05T19:40:17,488 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5723
2025-05-05T19:40:17,489 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,489 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9004-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,489 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:6983.0|#WorkerName:W-9004-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,489 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,529 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5601
2025-05-05T19:40:17,529 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5601
2025-05-05T19:40:17,529 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,529 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9002-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,529 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:7023.0|#WorkerName:W-9002-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,529 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,569 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5659
2025-05-05T19:40:17,569 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5659
2025-05-05T19:40:17,569 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,569 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9003-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,569 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:7063.0|#WorkerName:W-9003-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,570 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5687
2025-05-05T19:40:17,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5687
2025-05-05T19:40:17,617 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,617 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9006-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,618 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5637
2025-05-05T19:40:17,618 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5637
2025-05-05T19:40:17,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:7112.0|#WorkerName:W-9006-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,618 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,618 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9007-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,618 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:7112.0|#WorkerName:W-9007-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,618 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,670 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5773
2025-05-05T19:40:17,670 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 5773
2025-05-05T19:40:17,670 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,670 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - W-9005-drawn_humanoid_pose_estimator_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:17,670 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:7164.0|#WorkerName:W-9005-drawn_humanoid_pose_estimator_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,670 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445217
2025-05-05T19:40:17,845 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9009
2025-05-05T19:40:17,848 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,849 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35077
2025-05-05T19:40:17,849 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,849 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,849 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,849 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,849 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9009
2025-05-05T19:40:17,849 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9009
2025-05-05T19:40:17,851 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9009).
2025-05-05T19:40:17,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217851
2025-05-05T19:40:17,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217851
2025-05-05T19:40:17,851 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217851
2025-05-05T19:40:17,851 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217851
2025-05-05T19:40:17,856 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,858 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9011
2025-05-05T19:40:17,870 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,871 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35079
2025-05-05T19:40:17,871 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,871 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,871 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,871 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,872 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9011
2025-05-05T19:40:17,872 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9011
2025-05-05T19:40:17,875 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9011).
2025-05-05T19:40:17,877 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217877
2025-05-05T19:40:17,877 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217877
2025-05-05T19:40:17,877 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217877
2025-05-05T19:40:17,877 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217877
2025-05-05T19:40:17,884 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,894 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9013
2025-05-05T19:40:17,903 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9008
2025-05-05T19:40:17,903 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,904 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35082
2025-05-05T19:40:17,905 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,905 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,904 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,906 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9013
2025-05-05T19:40:17,906 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9013
2025-05-05T19:40:17,906 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,906 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,906 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35076
2025-05-05T19:40:17,907 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,907 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,907 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,907 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,907 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9008
2025-05-05T19:40:17,907 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9008
2025-05-05T19:40:17,909 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9013).
2025-05-05T19:40:17,909 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217909
2025-05-05T19:40:17,909 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217909
2025-05-05T19:40:17,909 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217909
2025-05-05T19:40:17,909 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217909
2025-05-05T19:40:17,912 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9010
2025-05-05T19:40:17,913 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9008).
2025-05-05T19:40:17,913 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217913
2025-05-05T19:40:17,913 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217913
2025-05-05T19:40:17,913 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217913
2025-05-05T19:40:17,913 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217913
2025-05-05T19:40:17,917 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,919 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,919 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,920 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35078
2025-05-05T19:40:17,920 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,920 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,920 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,920 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,920 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9010
2025-05-05T19:40:17,920 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9010
2025-05-05T19:40:17,923 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9010).
2025-05-05T19:40:17,923 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217923
2025-05-05T19:40:17,923 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217923
2025-05-05T19:40:17,923 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217923
2025-05-05T19:40:17,923 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217923
2025-05-05T19:40:17,928 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,936 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9014
2025-05-05T19:40:17,941 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,941 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35081
2025-05-05T19:40:17,941 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,942 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,941 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,941 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,942 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9014
2025-05-05T19:40:17,942 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9014
2025-05-05T19:40:17,946 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9014).
2025-05-05T19:40:17,946 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217946
2025-05-05T19:40:17,946 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217946
2025-05-05T19:40:17,946 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217946
2025-05-05T19:40:17,946 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217946
2025-05-05T19:40:17,946 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9012
2025-05-05T19:40:17,949 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Listening on addr:port: 127.0.0.1:9015
2025-05-05T19:40:17,953 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,953 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Successfully loaded /Users/bohan/miniconda3/envs/animated_drawings/lib/python3.8/site-packages/ts/configs/metrics.yaml.
2025-05-05T19:40:17,953 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35080
2025-05-05T19:40:17,953 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,953 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,954 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - [PID]35083
2025-05-05T19:40:17,954 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch worker started.
2025-05-05T19:40:17,954 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,954 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,954 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Python runtime: 3.8.13
2025-05-05T19:40:17,955 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,954 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,956 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9012
2025-05-05T19:40:17,956 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9012
2025-05-05T19:40:17,954 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-drawn_humanoid_detector_1.0 State change null -> WORKER_STARTED
2025-05-05T19:40:17,956 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9015
2025-05-05T19:40:17,956 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Connecting to: /127.0.0.1:9015
2025-05-05T19:40:17,962 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9015).
2025-05-05T19:40:17,962 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Connection accepted: ('127.0.0.1', 9012).
2025-05-05T19:40:17,963 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217963
2025-05-05T19:40:17,963 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217963
2025-05-05T19:40:17,963 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217963
2025-05-05T19:40:17,963 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217963
2025-05-05T19:40:17,963 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217963
2025-05-05T19:40:17,963 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd LOAD repeats 1 to backend at: 1746445217963
2025-05-05T19:40:17,963 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217963
2025-05-05T19:40:17,963 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445217963
2025-05-05T19:40:17,971 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:17,976 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - model_name: drawn_humanoid_detector, batchSize: 1
2025-05-05T19:40:18,337 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,337 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,337 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,337 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,337 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,337 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,337 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,338 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,377 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,377 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,377 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,377 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,395 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,395 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,395 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,395 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,406 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,406 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,407 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,407 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,410 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,411 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,411 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,411 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,434 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,434 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,434 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,434 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:18,483 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Your torch version is 1.13.0 which does not support torch.compile
2025-05-05T19:40:18,483 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - OpenVINO is not enabled
2025-05-05T19:40:18,484 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - proceeding without onnxruntime
2025-05-05T19:40:18,484 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Torch TensorRT not enabled
2025-05-05T19:40:21,640 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3763
2025-05-05T19:40:21,640 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3730
2025-05-05T19:40:21,640 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3677
2025-05-05T19:40:21,640 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3727
2025-05-05T19:40:21,640 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3788
2025-05-05T19:40:21,640 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3788
2025-05-05T19:40:21,640 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3694
2025-05-05T19:40:21,640 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3677
2025-05-05T19:40:21,640 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3677
2025-05-05T19:40:21,640 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3677
2025-05-05T19:40:21,641 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,640 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3727
2025-05-05T19:40:21,640 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3763
2025-05-05T19:40:21,641 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9008-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9009-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9015-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,640 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3730
2025-05-05T19:40:21,642 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,642 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,642 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9013-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,642 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9011-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,640 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3694
2025-05-05T19:40:21,642 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,642 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9014-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,641 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9012-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,642 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5907.0|#WorkerName:W-9013-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5907.0|#WorkerName:W-9015-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5907.0|#WorkerName:W-9014-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5908.0|#WorkerName:W-9009-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5908.0|#WorkerName:W-9012-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5908.0|#WorkerName:W-9008-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:4.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,642 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5908.0|#WorkerName:W-9011-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,643 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,659 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3736
2025-05-05T19:40:21,659 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 3736
2025-05-05T19:40:21,659 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,659 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - W-9010-drawn_humanoid_detector_1.0 State change WORKER_STARTED -> WORKER_MODEL_LOADED
2025-05-05T19:40:21,659 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - WorkerLoadTime.Milliseconds:5925.0|#WorkerName:W-9010-drawn_humanoid_detector_1.0,Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:40:21,659 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445221
2025-05-05T19:41:16,059 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.8280029296875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5725.96875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8234.046875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:41:16,060 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:76.7|#Level:Host|#hostname:192.168.31.54,timestamp:1746445276
2025-05-05T19:42:16,048 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.8245849609375|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5482.421875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8095.84375|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:42:16,049 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:77.7|#Level:Host|#hostname:192.168.31.54,timestamp:1746445336
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.82047653198242|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5625.140625|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:8301.203125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:16,030 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:77.1|#Level:Host|#hostname:192.168.31.54,timestamp:1746445396
2025-05-05T19:43:40,715 [INFO ] nioEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445420
2025-05-05T19:43:40,716 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445420715
2025-05-05T19:43:40,716 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445420715
2025-05-05T19:43:40,716 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445420716
2025-05-05T19:43:40,716 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445420716
2025-05-05T19:43:40,718 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:43:40,719 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746445420
2025-05-05T19:43:41,830 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1111.66|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445421,7e4b6e09-1608-413c-a309-544630b1ee40, pattern=[METRICS]
2025-05-05T19:43:41,830 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1111.66|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445421,7e4b6e09-1608-413c-a309-544630b1ee40, pattern=[METRICS]
2025-05-05T19:43:41,831 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7e4b6e09-1608-413c-a309-544630b1ee40
2025-05-05T19:43:41,831 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7e4b6e09-1608-413c-a309-544630b1ee40
2025-05-05T19:43:41,831 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1111.66|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:7e4b6e09-1608-413c-a309-544630b1ee40,timestamp:1746445421
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1111.87|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445421,7e4b6e09-1608-413c-a309-544630b1ee40, pattern=[METRICS]
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1111.87|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445421,7e4b6e09-1608-413c-a309-544630b1ee40, pattern=[METRICS]
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1111.87|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:7e4b6e09-1608-413c-a309-544630b1ee40,timestamp:1746445421
2025-05-05T19:43:41,831 [INFO ] W-9015-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60237 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1130
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1115788.833|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:82.292|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,832 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 82292, Backend time ns: 1116911291
2025-05-05T19:43:41,832 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 82292, Backend time ns: 1116911291
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1115
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1115
2025-05-05T19:43:41,832 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,921 [INFO ] nioEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445421
2025-05-05T19:43:41,922 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445421922
2025-05-05T19:43:41,922 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445421922
2025-05-05T19:43:41,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445421922
2025-05-05T19:43:41,922 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445421922
2025-05-05T19:43:41,924 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:43:41,924 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746445421
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:104.46|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445422,74f93eae-4725-4ba4-8997-66c6272aa081, pattern=[METRICS]
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:104.46|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445422,74f93eae-4725-4ba4-8997-66c6272aa081, pattern=[METRICS]
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:104.46|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:74f93eae-4725-4ba4-8997-66c6272aa081,timestamp:1746445422
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:104.7|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445422,74f93eae-4725-4ba4-8997-66c6272aa081, pattern=[METRICS]
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:104.7|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445422,74f93eae-4725-4ba4-8997-66c6272aa081, pattern=[METRICS]
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 74f93eae-4725-4ba4-8997-66c6272aa081
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 74f93eae-4725-4ba4-8997-66c6272aa081
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:104.7|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:74f93eae-4725-4ba4-8997-66c6272aa081,timestamp:1746445422
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60248 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 111
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445422
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:107323.333|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445422
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:133.541|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445422
2025-05-05T19:43:42,029 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 133541, Backend time ns: 107472625
2025-05-05T19:43:42,029 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 133541, Backend time ns: 107472625
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445422
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 107
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 107
2025-05-05T19:43:42,029 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445422
2025-05-05T19:44:16,045 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.80316543579102|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5745.109375|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6938.625|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:16,046 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:76.6|#Level:Host|#hostname:192.168.31.54,timestamp:1746445456
2025-05-05T19:44:27,628 [INFO ] nioEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445467
2025-05-05T19:44:27,628 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445467628
2025-05-05T19:44:27,628 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445467628
2025-05-05T19:44:27,629 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445467629
2025-05-05T19:44:27,629 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445467629
2025-05-05T19:44:27,631 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:44:27,631 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746445467
2025-05-05T19:44:28,463 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:831.88|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445468,8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb, pattern=[METRICS]
2025-05-05T19:44:28,463 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:831.88|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445468,8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb, pattern=[METRICS]
2025-05-05T19:44:28,463 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb
2025-05-05T19:44:28,463 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb
2025-05-05T19:44:28,463 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:831.88|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb,timestamp:1746445468
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60518 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 838
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:832.35|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445468,8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb, pattern=[METRICS]
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:832.35|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445468,8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb, pattern=[METRICS]
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445468
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:832.35|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:8c0fc6b4-dd4c-4ecb-91bc-8b7bb60520eb,timestamp:1746445468
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:835130.625|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445468
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:70.459|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445468
2025-05-05T19:44:28,464 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 70459, Backend time ns: 835677458
2025-05-05T19:44:28,464 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 70459, Backend time ns: 835677458
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445468
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 834
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 834
2025-05-05T19:44:28,464 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445468
2025-05-05T19:44:29,059 [INFO ] nioEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:44:29,059 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445469059
2025-05-05T19:44:29,059 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445469059
2025-05-05T19:44:29,059 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445469059
2025-05-05T19:44:29,059 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445469059
2025-05-05T19:44:29,061 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:44:29,061 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746445469
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:99.23|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445469,97b81482-1943-4730-9247-68a09599f9b3, pattern=[METRICS]
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:99.23|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445469,97b81482-1943-4730-9247-68a09599f9b3, pattern=[METRICS]
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:99.23|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:97b81482-1943-4730-9247-68a09599f9b3,timestamp:1746445469
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:99.49|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445469,97b81482-1943-4730-9247-68a09599f9b3, pattern=[METRICS]
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:99.49|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445469,97b81482-1943-4730-9247-68a09599f9b3, pattern=[METRICS]
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:99.49|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:97b81482-1943-4730-9247-68a09599f9b3,timestamp:1746445469
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 97b81482-1943-4730-9247-68a09599f9b3
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 97b81482-1943-4730-9247-68a09599f9b3
2025-05-05T19:44:29,161 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60527 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 104
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:102517.333|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:60.542|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:44:29,162 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 60542, Backend time ns: 102722125
2025-05-05T19:44:29,162 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 60542, Backend time ns: 102722125
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T19:44:29,162 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445469
2025-05-05T19:45:16,056 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,056 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.78546142578125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,056 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,057 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,057 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5878.0625|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,057 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6617.734375|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:16,057 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:76.1|#Level:Host|#hostname:192.168.31.54,timestamp:1746445516
2025-05-05T19:45:30,306 [INFO ] nioEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445530
2025-05-05T19:45:30,306 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445530306
2025-05-05T19:45:30,306 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445530306
2025-05-05T19:45:30,306 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445530306
2025-05-05T19:45:30,306 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445530306
2025-05-05T19:45:30,308 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:45:30,308 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746445530
2025-05-05T19:45:31,160 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:851.4|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,b050d0f3-47cd-4cc1-9a90-a5b75202fd20, pattern=[METRICS]
2025-05-05T19:45:31,160 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:851.4|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,b050d0f3-47cd-4cc1-9a90-a5b75202fd20, pattern=[METRICS]
2025-05-05T19:45:31,160 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId b050d0f3-47cd-4cc1-9a90-a5b75202fd20
2025-05-05T19:45:31,160 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId b050d0f3-47cd-4cc1-9a90-a5b75202fd20
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60844 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 857
2025-05-05T19:45:31,160 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:851.4|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:b050d0f3-47cd-4cc1-9a90-a5b75202fd20,timestamp:1746445531
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:851.73|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,b050d0f3-47cd-4cc1-9a90-a5b75202fd20, pattern=[METRICS]
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:851.73|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,b050d0f3-47cd-4cc1-9a90-a5b75202fd20, pattern=[METRICS]
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:851.73|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:192.168.31.54,requestID:b050d0f3-47cd-4cc1-9a90-a5b75202fd20,timestamp:1746445531
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:854299.625|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:49.167|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,161 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 49167, Backend time ns: 854983125
2025-05-05T19:45:31,161 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 49167, Backend time ns: 854983125
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 854
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 854
2025-05-05T19:45:31,161 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,280 [INFO ] nioEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,280 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445531280
2025-05-05T19:45:31,280 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445531280
2025-05-05T19:45:31,280 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445531280
2025-05-05T19:45:31,280 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445531280
2025-05-05T19:45:31,282 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:45:31,282 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746445531
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:121.5|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,6cb145e8-39f6-4b3c-8195-007ca26133cf, pattern=[METRICS]
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:121.5|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,6cb145e8-39f6-4b3c-8195-007ca26133cf, pattern=[METRICS]
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:121.5|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:6cb145e8-39f6-4b3c-8195-007ca26133cf,timestamp:1746445531
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:121.77|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,6cb145e8-39f6-4b3c-8195-007ca26133cf, pattern=[METRICS]
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:121.77|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:192.168.31.54,1746445531,6cb145e8-39f6-4b3c-8195-007ca26133cf, pattern=[METRICS]
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:121.77|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:192.168.31.54,requestID:6cb145e8-39f6-4b3c-8195-007ca26133cf,timestamp:1746445531
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 6cb145e8-39f6-4b3c-8195-007ca26133cf
2025-05-05T19:45:31,404 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 6cb145e8-39f6-4b3c-8195-007ca26133cf
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:60853 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 125
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:124610.333|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:51.75|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,405 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 51750, Backend time ns: 124838458
2025-05-05T19:45:31,405 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 51750, Backend time ns: 124838458
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 124
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 124
2025-05-05T19:45:31,405 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445531
2025-05-05T19:46:16,035 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.72738265991211|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5423.28125|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:6898.421875|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:46:16,036 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:77.9|#Level:Host|#hostname:192.168.31.54,timestamp:1746445576
2025-05-05T19:47:16,049 [INFO ] pool-3-thread-1 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - DiskAvailable.Gigabytes:67.68992614746094|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - MemoryAvailable.Megabytes:5300.65625|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUsed.Megabytes:7769.765625|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:47:16,050 [INFO ] pool-3-thread-1 TS_METRICS - MemoryUtilization.Percent:78.4|#Level:Host|#hostname:bohan.local,timestamp:1746445636
2025-05-05T19:48:16,045 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.61170959472656|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.0|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5155.890625|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7481.890625|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:48:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.0|#Level:Host|#hostname:bohan.local,timestamp:1746445696
2025-05-05T19:49:16,036 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.58258819580078|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:4705.75|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7947.28125|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:49:16,037 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:80.9|#Level:Host|#hostname:bohan.local,timestamp:1746445756
2025-05-05T19:50:16,042 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,042 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.56573486328125|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,042 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,042 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,042 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5109.171875|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,043 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7637.390625|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:50:16,043 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.2|#Level:Host|#hostname:bohan.local,timestamp:1746445816
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.56366729736328|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5093.28125|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7737.640625|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.3|#Level:Host|#hostname:bohan.local,timestamp:1746445876
2025-05-05T19:51:45,471 [INFO ] nioEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445905
2025-05-05T19:51:45,472 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445905472
2025-05-05T19:51:45,472 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445905472
2025-05-05T19:51:45,472 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445905472
2025-05-05T19:51:45,472 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445905472
2025-05-05T19:51:45,475 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:51:45,476 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746445905
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1054.59|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,319fe1ae-71b4-45a0-a712-c69782065e1d, pattern=[METRICS]
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1054.59|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,319fe1ae-71b4-45a0-a712-c69782065e1d, pattern=[METRICS]
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 319fe1ae-71b4-45a0-a712-c69782065e1d
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 319fe1ae-71b4-45a0-a712-c69782065e1d
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:63898 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1062
2025-05-05T19:51:46,531 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1054.59|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:319fe1ae-71b4-45a0-a712-c69782065e1d,timestamp:1746445906
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1054.85|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,319fe1ae-71b4-45a0-a712-c69782065e1d, pattern=[METRICS]
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1054.85|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,319fe1ae-71b4-45a0-a712-c69782065e1d, pattern=[METRICS]
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1054.85|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:319fe1ae-71b4-45a0-a712-c69782065e1d,timestamp:1746445906
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1059315.042|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:263.708|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,532 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 263708, Backend time ns: 1060247917
2025-05-05T19:51:46,532 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 263708, Backend time ns: 1060247917
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1059
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1059
2025-05-05T19:51:46,532 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,617 [INFO ] nioEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,618 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445906618
2025-05-05T19:51:46,618 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746445906618
2025-05-05T19:51:46,618 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445906618
2025-05-05T19:51:46,618 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746445906618
2025-05-05T19:51:46,620 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:51:46,620 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746445906
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:103.74|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,95aa2c4a-f478-432b-b707-9573ce6b282d, pattern=[METRICS]
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:103.74|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,95aa2c4a-f478-432b-b707-9573ce6b282d, pattern=[METRICS]
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:103.74|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:95aa2c4a-f478-432b-b707-9573ce6b282d,timestamp:1746445906
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.99|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,95aa2c4a-f478-432b-b707-9573ce6b282d, pattern=[METRICS]
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.99|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746445906,95aa2c4a-f478-432b-b707-9573ce6b282d, pattern=[METRICS]
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:103.99|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:95aa2c4a-f478-432b-b707-9573ce6b282d,timestamp:1746445906
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 95aa2c4a-f478-432b-b707-9573ce6b282d
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 95aa2c4a-f478-432b-b707-9573ce6b282d
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:63903 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 119
2025-05-05T19:51:46,724 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:106854.375|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:42.167|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,725 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 42167, Backend time ns: 107132542
2025-05-05T19:51:46,725 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 42167, Backend time ns: 107132542
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 106
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 106
2025-05-05T19:51:46,725 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746445906
2025-05-05T19:52:16,037 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.53091812133789|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5700.875|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:5838.8125|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:52:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:76.8|#Level:Host|#hostname:bohan.local,timestamp:1746445936
2025-05-05T19:53:16,034 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.49659729003906|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5090.5625|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7519.59375|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:16,035 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.3|#Level:Host|#hostname:bohan.local,timestamp:1746445996
2025-05-05T19:53:31,069 [INFO ] nioEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446011
2025-05-05T19:53:31,069 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446011069
2025-05-05T19:53:31,069 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446011069
2025-05-05T19:53:31,069 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446011069
2025-05-05T19:53:31,069 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446011069
2025-05-05T19:53:31,071 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:53:31,071 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446011
2025-05-05T19:53:32,044 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:972.63|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,c0bd9d8e-07e6-452e-a06a-4527df6b4d65, pattern=[METRICS]
2025-05-05T19:53:32,045 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId c0bd9d8e-07e6-452e-a06a-4527df6b4d65
2025-05-05T19:53:32,044 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:972.63|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,c0bd9d8e-07e6-452e-a06a-4527df6b4d65, pattern=[METRICS]
2025-05-05T19:53:32,045 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId c0bd9d8e-07e6-452e-a06a-4527df6b4d65
2025-05-05T19:53:32,045 [INFO ] W-9011-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:64810 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 977
2025-05-05T19:53:32,045 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:972.63|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:c0bd9d8e-07e6-452e-a06a-4527df6b4d65,timestamp:1746446012
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:972.83|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,c0bd9d8e-07e6-452e-a06a-4527df6b4d65, pattern=[METRICS]
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:972.83|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,c0bd9d8e-07e6-452e-a06a-4527df6b4d65, pattern=[METRICS]
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:972.83|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:c0bd9d8e-07e6-452e-a06a-4527df6b4d65,timestamp:1746446012
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:976200.083|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:80.125|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,046 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 80125, Backend time ns: 977321458
2025-05-05T19:53:32,046 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 80125, Backend time ns: 977321458
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 976
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 976
2025-05-05T19:53:32,046 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,070 [INFO ] nioEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,070 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446012070
2025-05-05T19:53:32,070 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446012070
2025-05-05T19:53:32,070 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446012070
2025-05-05T19:53:32,070 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446012070
2025-05-05T19:53:32,072 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:53:32,073 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446012
2025-05-05T19:53:32,173 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.4|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,7b0c1b63-3308-4649-85f7-0ef9a790831d, pattern=[METRICS]
2025-05-05T19:53:32,173 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.4|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,7b0c1b63-3308-4649-85f7-0ef9a790831d, pattern=[METRICS]
2025-05-05T19:53:32,173 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:100.4|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:7b0c1b63-3308-4649-85f7-0ef9a790831d,timestamp:1746446012
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,7b0c1b63-3308-4649-85f7-0ef9a790831d, pattern=[METRICS]
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446012,7b0c1b63-3308-4649-85f7-0ef9a790831d, pattern=[METRICS]
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7b0c1b63-3308-4649-85f7-0ef9a790831d
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7b0c1b63-3308-4649-85f7-0ef9a790831d
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:100.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:7b0c1b63-3308-4649-85f7-0ef9a790831d,timestamp:1746446012
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:64817 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 105
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:103471.417|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:73.792|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,174 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 73792, Backend time ns: 103669458
2025-05-05T19:53:32,174 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 73792, Backend time ns: 103669458
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 104
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 104
2025-05-05T19:53:32,174 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446012
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.46067810058594|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5120.453125|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:6997.75|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:16,048 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.2|#Level:Host|#hostname:bohan.local,timestamp:1746446056
2025-05-05T19:54:33,457 [INFO ] nioEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446073
2025-05-05T19:54:33,457 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446073457
2025-05-05T19:54:33,457 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446073457
2025-05-05T19:54:33,458 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446073458
2025-05-05T19:54:33,458 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446073458
2025-05-05T19:54:33,459 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:54:33,459 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446073
2025-05-05T19:54:34,489 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 5c6596ee-e16c-4c16-80a6-f697df235981
2025-05-05T19:54:34,489 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1028.26|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,5c6596ee-e16c-4c16-80a6-f697df235981, pattern=[METRICS]
2025-05-05T19:54:34,489 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 5c6596ee-e16c-4c16-80a6-f697df235981
2025-05-05T19:54:34,489 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1028.26|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,5c6596ee-e16c-4c16-80a6-f697df235981, pattern=[METRICS]
2025-05-05T19:54:34,490 [INFO ] W-9008-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:65235 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1034
2025-05-05T19:54:34,490 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1028.26|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:5c6596ee-e16c-4c16-80a6-f697df235981,timestamp:1746446074
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1028.46|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,5c6596ee-e16c-4c16-80a6-f697df235981, pattern=[METRICS]
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1028.46|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,5c6596ee-e16c-4c16-80a6-f697df235981, pattern=[METRICS]
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1028.46|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:5c6596ee-e16c-4c16-80a6-f697df235981,timestamp:1746446074
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1032280.458|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:54.75|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,491 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 54750, Backend time ns: 1033565833
2025-05-05T19:54:34,491 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 54750, Backend time ns: 1033565833
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1031
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1031
2025-05-05T19:54:34,491 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:3.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,516 [INFO ] nioEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,516 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446074516
2025-05-05T19:54:34,516 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446074516
2025-05-05T19:54:34,516 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446074516
2025-05-05T19:54:34,516 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446074516
2025-05-05T19:54:34,518 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:54:34,518 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446074
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:98.66|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,ca10fdae-38f6-4f3d-a5de-b8f2014e5208, pattern=[METRICS]
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:98.66|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,ca10fdae-38f6-4f3d-a5de-b8f2014e5208, pattern=[METRICS]
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:98.66|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:ca10fdae-38f6-4f3d-a5de-b8f2014e5208,timestamp:1746446074
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:98.86|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,ca10fdae-38f6-4f3d-a5de-b8f2014e5208, pattern=[METRICS]
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:98.86|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446074,ca10fdae-38f6-4f3d-a5de-b8f2014e5208, pattern=[METRICS]
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:98.86|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:ca10fdae-38f6-4f3d-a5de-b8f2014e5208,timestamp:1746446074
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId ca10fdae-38f6-4f3d-a5de-b8f2014e5208
2025-05-05T19:54:34,617 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId ca10fdae-38f6-4f3d-a5de-b8f2014e5208
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:65240 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 103
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:101665.875|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:74.291|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,618 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 74291, Backend time ns: 101823875
2025-05-05T19:54:34,618 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 74291, Backend time ns: 101823875
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 101
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 101
2025-05-05T19:54:34,618 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446074
2025-05-05T19:55:16,032 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.43007278442383|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:4921.234375|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7190.234375|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:80.0|#Level:Host|#hostname:bohan.local,timestamp:1746446116
2025-05-05T19:55:25,125 [INFO ] nioEventLoopGroup-3-13 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446125
2025-05-05T19:55:25,125 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446125125
2025-05-05T19:55:25,125 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446125125
2025-05-05T19:55:25,125 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446125125
2025-05-05T19:55:25,125 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446125125
2025-05-05T19:55:25,127 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:55:25,127 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446125
2025-05-05T19:55:26,083 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:955.07|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,08fa4bb7-8459-4148-9fa3-7d4e21d118d0, pattern=[METRICS]
2025-05-05T19:55:26,083 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 08fa4bb7-8459-4148-9fa3-7d4e21d118d0
2025-05-05T19:55:26,083 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 08fa4bb7-8459-4148-9fa3-7d4e21d118d0
2025-05-05T19:55:26,083 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:955.07|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,08fa4bb7-8459-4148-9fa3-7d4e21d118d0, pattern=[METRICS]
2025-05-05T19:55:26,084 [INFO ] W-9014-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:49169 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 960
2025-05-05T19:55:26,084 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:955.07|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:08fa4bb7-8459-4148-9fa3-7d4e21d118d0,timestamp:1746446126
2025-05-05T19:55:26,084 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:955.27|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,08fa4bb7-8459-4148-9fa3-7d4e21d118d0, pattern=[METRICS]
2025-05-05T19:55:26,084 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:955.27|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,08fa4bb7-8459-4148-9fa3-7d4e21d118d0, pattern=[METRICS]
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:955.27|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:08fa4bb7-8459-4148-9fa3-7d4e21d118d0,timestamp:1746446126
2025-05-05T19:55:26,084 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:958575.208|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:52.041|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,085 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 52041, Backend time ns: 959651084
2025-05-05T19:55:26,085 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 52041, Backend time ns: 959651084
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 958
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 958
2025-05-05T19:55:26,085 [INFO ] W-9014-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,108 [INFO ] nioEventLoopGroup-3-14 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,108 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446126108
2025-05-05T19:55:26,108 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446126108
2025-05-05T19:55:26,108 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446126108
2025-05-05T19:55:26,108 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446126108
2025-05-05T19:55:26,116 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:55:26,116 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446126
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.79|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,29aad430-8f91-4201-84da-0f532fced767, pattern=[METRICS]
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.79|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,29aad430-8f91-4201-84da-0f532fced767, pattern=[METRICS]
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:100.79|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:29aad430-8f91-4201-84da-0f532fced767,timestamp:1746446126
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:101.07|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,29aad430-8f91-4201-84da-0f532fced767, pattern=[METRICS]
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:101.07|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446126,29aad430-8f91-4201-84da-0f532fced767, pattern=[METRICS]
2025-05-05T19:55:26,211 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:101.07|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:29aad430-8f91-4201-84da-0f532fced767,timestamp:1746446126
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 29aad430-8f91-4201-84da-0f532fced767
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 29aad430-8f91-4201-84da-0f532fced767
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:49176 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 105
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:103828.708|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:44.5|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,212 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 44500, Backend time ns: 104001458
2025-05-05T19:55:26,212 [DEBUG] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 44500, Backend time ns: 104001458
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 103
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 103
2025-05-05T19:55:26,212 [INFO ] W-9007-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446126
2025-05-05T19:56:16,037 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.38289260864258|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:4556.265625|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7742.25|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:56:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:81.5|#Level:Host|#hostname:bohan.local,timestamp:1746446176
2025-05-05T19:57:16,056 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:67.35095977783203|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.1|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:4521.8125|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7315.125|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:16,057 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:81.6|#Level:Host|#hostname:bohan.local,timestamp:1746446236
2025-05-05T19:57:33,308 [INFO ] nioEventLoopGroup-3-15 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446253
2025-05-05T19:57:33,309 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446253309
2025-05-05T19:57:33,309 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446253309
2025-05-05T19:57:33,309 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446253309
2025-05-05T19:57:33,309 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446253309
2025-05-05T19:57:33,318 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/637eace9cddf4a078cc47a07d569f573/latest.pth
2025-05-05T19:57:33,318 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446253
2025-05-05T19:57:34,405 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1087.03|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,71884b1a-34d5-4374-bb2d-bd07cfe6164d, pattern=[METRICS]
2025-05-05T19:57:34,405 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1087.03|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,71884b1a-34d5-4374-bb2d-bd07cfe6164d, pattern=[METRICS]
2025-05-05T19:57:34,405 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1087.03|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:71884b1a-34d5-4374-bb2d-bd07cfe6164d,timestamp:1746446254
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 71884b1a-34d5-4374-bb2d-bd07cfe6164d
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 71884b1a-34d5-4374-bb2d-bd07cfe6164d
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1087.38|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,71884b1a-34d5-4374-bb2d-bd07cfe6164d, pattern=[METRICS]
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1087.38|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,71884b1a-34d5-4374-bb2d-bd07cfe6164d, pattern=[METRICS]
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1087.38|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:71884b1a-34d5-4374-bb2d-bd07cfe6164d,timestamp:1746446254
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:50651 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1102
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1096809.583|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:132.125|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,406 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 132125, Backend time ns: 1097062125
2025-05-05T19:57:34,406 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 132125, Backend time ns: 1097062125
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1097
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1097
2025-05-05T19:57:34,406 [INFO ] W-9010-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,477 [INFO ] nioEventLoopGroup-3-16 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,478 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446254478
2025-05-05T19:57:34,478 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446254478
2025-05-05T19:57:34,478 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446254478
2025-05-05T19:57:34,478 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446254478
2025-05-05T19:57:34,480 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - load checkpoint from local path: /var/folders/m_/lpp0z32x0qv6tbr9q6sbyglm0000gn/T/models/56e9d42ae5cb400e800c88aba28df445/best_AP_epoch_72.pth
2025-05-05T19:57:34,480 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446254
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:102.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2, pattern=[METRICS]
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:102.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2, pattern=[METRICS]
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:102.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2,timestamp:1746446254
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:102.55|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2, pattern=[METRICS]
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:102.55|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446254,84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2, pattern=[METRICS]
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:102.55|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:84f12cf4-9a6a-4d5f-a0fb-20a3f480dfc2,timestamp:1746446254
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:50660 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 108
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:105654.959|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,583 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:66.375|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,584 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 66375, Backend time ns: 105926625
2025-05-05T19:57:34,584 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 66375, Backend time ns: 105926625
2025-05-05T19:57:34,584 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:57:34,584 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 105
2025-05-05T19:57:34,584 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 105
2025-05-05T19:57:34,584 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446254
2025-05-05T19:58:16,023 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.31153106689453|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.3|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5378.734375|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:6272.28125|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:16,024 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.1|#Level:Host|#hostname:bohan.local,timestamp:1746446296
2025-05-05T19:58:28,882 [INFO ] nioEventLoopGroup-3-1 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446308
2025-05-05T19:58:28,882 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446308882
2025-05-05T19:58:28,882 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446308882
2025-05-05T19:58:28,882 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446308882
2025-05-05T19:58:28,882 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446308882
2025-05-05T19:58:28,884 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446308
2025-05-05T19:58:29,826 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:941.78|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446309,711e720c-bb8c-44dc-a456-d916a1964df5, pattern=[METRICS]
2025-05-05T19:58:29,826 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:941.78|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446309,711e720c-bb8c-44dc-a456-d916a1964df5, pattern=[METRICS]
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 711e720c-bb8c-44dc-a456-d916a1964df5
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 711e720c-bb8c-44dc-a456-d916a1964df5
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:941.78|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:711e720c-bb8c-44dc-a456-d916a1964df5,timestamp:1746446309
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51023 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 950
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:942.37|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446309,711e720c-bb8c-44dc-a456-d916a1964df5, pattern=[METRICS]
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:942.37|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446309,711e720c-bb8c-44dc-a456-d916a1964df5, pattern=[METRICS]
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:942.37|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:711e720c-bb8c-44dc-a456-d916a1964df5,timestamp:1746446309
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:945062.834|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:132.417|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,827 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 132417, Backend time ns: 945386208
2025-05-05T19:58:29,827 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 132417, Backend time ns: 945386208
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 945
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 945
2025-05-05T19:58:29,827 [INFO ] W-9015-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,895 [INFO ] nioEventLoopGroup-3-2 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446309
2025-05-05T19:58:29,895 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446309895
2025-05-05T19:58:29,895 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446309895
2025-05-05T19:58:29,895 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446309895
2025-05-05T19:58:29,895 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446309895
2025-05-05T19:58:29,896 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446309
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:108.63|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446310,40240ba4-391e-4e65-9cbe-1d45d74569ab, pattern=[METRICS]
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:108.63|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446310,40240ba4-391e-4e65-9cbe-1d45d74569ab, pattern=[METRICS]
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:108.63|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:40240ba4-391e-4e65-9cbe-1d45d74569ab,timestamp:1746446310
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:108.83|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446310,40240ba4-391e-4e65-9cbe-1d45d74569ab, pattern=[METRICS]
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:108.83|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446310,40240ba4-391e-4e65-9cbe-1d45d74569ab, pattern=[METRICS]
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:108.83|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:40240ba4-391e-4e65-9cbe-1d45d74569ab,timestamp:1746446310
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 40240ba4-391e-4e65-9cbe-1d45d74569ab
2025-05-05T19:58:30,005 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 40240ba4-391e-4e65-9cbe-1d45d74569ab
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:51030 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 114
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446310
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:110941.917|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446310
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:60.917|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446310
2025-05-05T19:58:30,006 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 60917, Backend time ns: 111064333
2025-05-05T19:58:30,006 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 60917, Backend time ns: 111064333
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446310
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 110
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 110
2025-05-05T19:58:30,006 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446310
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.23245620727539|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5339.078125|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:6867.828125|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T19:59:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.3|#Level:Host|#hostname:bohan.local,timestamp:1746446356
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.22758102416992|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5184.078125|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7321.78125|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:00:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.9|#Level:Host|#hostname:bohan.local,timestamp:1746446416
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.22545623779297|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5279.796875|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7450.5625|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:01:16,029 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.5|#Level:Host|#hostname:bohan.local,timestamp:1746446476
2025-05-05T20:02:16,029 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.2229118347168|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5345.828125|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8008.0625|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:02:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.2|#Level:Host|#hostname:bohan.local,timestamp:1746446536
2025-05-05T20:03:16,030 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.22164916992188|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,031 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,031 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5354.75|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8042.9375|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:03:16,031 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.2|#Level:Host|#hostname:bohan.local,timestamp:1746446596
2025-05-05T20:04:16,040 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.22002410888672|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5281.984375|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8115.53125|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:04:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.5|#Level:Host|#hostname:bohan.local,timestamp:1746446656
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.21612548828125|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5512.140625|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7913.4375|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:05:16,027 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:77.6|#Level:Host|#hostname:bohan.local,timestamp:1746446716
2025-05-05T20:06:16,039 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.24052429199219|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5385.6875|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7940.03125|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:16,040 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.1|#Level:Host|#hostname:bohan.local,timestamp:1746446776
2025-05-05T20:06:22,673 [INFO ] nioEventLoopGroup-3-3 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446782
2025-05-05T20:06:22,674 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446782673
2025-05-05T20:06:22,674 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446782673
2025-05-05T20:06:22,674 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446782674
2025-05-05T20:06:22,674 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446782674
2025-05-05T20:06:22,675 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446782
2025-05-05T20:06:23,720 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1044.89|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,8b900fbf-ab51-453e-9f6e-09981a920ffb, pattern=[METRICS]
2025-05-05T20:06:23,721 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 8b900fbf-ab51-453e-9f6e-09981a920ffb
2025-05-05T20:06:23,720 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1044.89|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,8b900fbf-ab51-453e-9f6e-09981a920ffb, pattern=[METRICS]
2025-05-05T20:06:23,721 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 8b900fbf-ab51-453e-9f6e-09981a920ffb
2025-05-05T20:06:23,721 [INFO ] W-9013-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54208 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1049
2025-05-05T20:06:23,721 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1044.89|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:8b900fbf-ab51-453e-9f6e-09981a920ffb,timestamp:1746446783
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1045.07|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,8b900fbf-ab51-453e-9f6e-09981a920ffb, pattern=[METRICS]
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1045.07|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,8b900fbf-ab51-453e-9f6e-09981a920ffb, pattern=[METRICS]
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1045.07|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:8b900fbf-ab51-453e-9f6e-09981a920ffb,timestamp:1746446783
2025-05-05T20:06:23,721 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1047855.958|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:134.833|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,722 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 134833, Backend time ns: 1048362458
2025-05-05T20:06:23,722 [DEBUG] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 134833, Backend time ns: 1048362458
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1047
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1047
2025-05-05T20:06:23,722 [INFO ] W-9013-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,735 [INFO ] nioEventLoopGroup-3-4 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,735 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446783735
2025-05-05T20:06:23,735 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446783735
2025-05-05T20:06:23,735 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446783735
2025-05-05T20:06:23,735 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446783735
2025-05-05T20:06:23,736 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,5f3175d6-67b2-4279-997b-0720043db693, pattern=[METRICS]
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,5f3175d6-67b2-4279-997b-0720043db693, pattern=[METRICS]
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:100.26|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:5f3175d6-67b2-4279-997b-0720043db693,timestamp:1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.43|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,5f3175d6-67b2-4279-997b-0720043db693, pattern=[METRICS]
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.43|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446783,5f3175d6-67b2-4279-997b-0720043db693, pattern=[METRICS]
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:100.43|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:5f3175d6-67b2-4279-997b-0720043db693,timestamp:1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 5f3175d6-67b2-4279-997b-0720043db693
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 5f3175d6-67b2-4279-997b-0720043db693
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54214 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 103
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:102233.208|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:61.458|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,837 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 61458, Backend time ns: 102369875
2025-05-05T20:06:23,837 [DEBUG] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 61458, Backend time ns: 102369875
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T20:06:23,837 [INFO ] W-9000-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446783
2025-05-05T20:07:16,040 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:100.0|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.1676139831543|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5383.53125|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7653.78125|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:16,041 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.1|#Level:Host|#hostname:bohan.local,timestamp:1746446836
2025-05-05T20:07:33,732 [INFO ] nioEventLoopGroup-3-5 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446853
2025-05-05T20:07:33,733 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446853733
2025-05-05T20:07:33,733 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446853733
2025-05-05T20:07:33,733 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446853733
2025-05-05T20:07:33,733 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446853733
2025-05-05T20:07:33,734 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446853
2025-05-05T20:07:34,758 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1023.58|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,6dd9c4fa-6a19-4ccb-8ada-0acdcf249405, pattern=[METRICS]
2025-05-05T20:07:34,758 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1023.58|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,6dd9c4fa-6a19-4ccb-8ada-0acdcf249405, pattern=[METRICS]
2025-05-05T20:07:34,758 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 6dd9c4fa-6a19-4ccb-8ada-0acdcf249405
2025-05-05T20:07:34,758 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 6dd9c4fa-6a19-4ccb-8ada-0acdcf249405
2025-05-05T20:07:34,758 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1023.58|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:6dd9c4fa-6a19-4ccb-8ada-0acdcf249405,timestamp:1746446854
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54735 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1027
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1024.11|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,6dd9c4fa-6a19-4ccb-8ada-0acdcf249405, pattern=[METRICS]
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1024.11|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,6dd9c4fa-6a19-4ccb-8ada-0acdcf249405, pattern=[METRICS]
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1024.11|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:6dd9c4fa-6a19-4ccb-8ada-0acdcf249405,timestamp:1746446854
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1025957.459|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:42.792|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,759 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 42792, Backend time ns: 1026295125
2025-05-05T20:07:34,759 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 42792, Backend time ns: 1026295125
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1025
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1025
2025-05-05T20:07:34,759 [INFO ] W-9009-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,773 [INFO ] nioEventLoopGroup-3-6 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,773 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446854773
2025-05-05T20:07:34,773 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446854773
2025-05-05T20:07:34,773 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446854773
2025-05-05T20:07:34,773 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446854773
2025-05-05T20:07:34,775 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446854
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.12|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,fcc91aa5-b6a0-4ea7-9668-23a4109f9087, pattern=[METRICS]
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:100.12|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,fcc91aa5-b6a0-4ea7-9668-23a4109f9087, pattern=[METRICS]
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:100.12|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:fcc91aa5-b6a0-4ea7-9668-23a4109f9087,timestamp:1746446854
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.3|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,fcc91aa5-b6a0-4ea7-9668-23a4109f9087, pattern=[METRICS]
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:100.3|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446854,fcc91aa5-b6a0-4ea7-9668-23a4109f9087, pattern=[METRICS]
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:100.3|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:fcc91aa5-b6a0-4ea7-9668-23a4109f9087,timestamp:1746446854
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId fcc91aa5-b6a0-4ea7-9668-23a4109f9087
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId fcc91aa5-b6a0-4ea7-9668-23a4109f9087
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:54742 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 103
2025-05-05T20:07:34,875 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:102243.875|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:48.5|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,876 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 48500, Backend time ns: 102377666
2025-05-05T20:07:34,876 [DEBUG] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 48500, Backend time ns: 102377666
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 102
2025-05-05T20:07:34,876 [INFO ] W-9004-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446854
2025-05-05T20:08:16,045 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,045 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.16279602050781|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,045 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,045 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5224.90625|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7830.4375|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,046 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.7|#Level:Host|#hostname:bohan.local,timestamp:1746446896
2025-05-05T20:08:16,518 [INFO ] nioEventLoopGroup-3-7 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446896
2025-05-05T20:08:16,518 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446896518
2025-05-05T20:08:16,518 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446896518
2025-05-05T20:08:16,518 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446896518
2025-05-05T20:08:16,518 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446896518
2025-05-05T20:08:16,520 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746446896
2025-05-05T20:08:17,559 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1039.03|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,7d51317d-ead7-4e0a-ac27-66cf65f1cc2c, pattern=[METRICS]
2025-05-05T20:08:17,559 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1039.03|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,7d51317d-ead7-4e0a-ac27-66cf65f1cc2c, pattern=[METRICS]
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7d51317d-ead7-4e0a-ac27-66cf65f1cc2c
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 7d51317d-ead7-4e0a-ac27-66cf65f1cc2c
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:55047 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1043
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1039.03|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:7d51317d-ead7-4e0a-ac27-66cf65f1cc2c,timestamp:1746446897
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1039.3|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,7d51317d-ead7-4e0a-ac27-66cf65f1cc2c, pattern=[METRICS]
2025-05-05T20:08:17,560 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1039.3|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,7d51317d-ead7-4e0a-ac27-66cf65f1cc2c, pattern=[METRICS]
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1039.3|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:7d51317d-ead7-4e0a-ac27-66cf65f1cc2c,timestamp:1746446897
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1041507.417|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:138.167|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,561 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 138167, Backend time ns: 1042260625
2025-05-05T20:08:17,561 [DEBUG] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 138167, Backend time ns: 1042260625
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1041
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1041
2025-05-05T20:08:17,561 [INFO ] W-9012-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:2.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,586 [INFO ] nioEventLoopGroup-3-8 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,586 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446897586
2025-05-05T20:08:17,586 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746446897586
2025-05-05T20:08:17,586 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446897586
2025-05-05T20:08:17,586 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746446897586
2025-05-05T20:08:17,588 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746446897
2025-05-05T20:08:17,691 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:103.19|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,0b78b46b-3997-4c89-9164-6a8a2876a115, pattern=[METRICS]
2025-05-05T20:08:17,691 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:103.19|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,0b78b46b-3997-4c89-9164-6a8a2876a115, pattern=[METRICS]
2025-05-05T20:08:17,691 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:103.19|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:0b78b46b-3997-4c89-9164-6a8a2876a115,timestamp:1746446897
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.84|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,0b78b46b-3997-4c89-9164-6a8a2876a115, pattern=[METRICS]
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.84|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746446897,0b78b46b-3997-4c89-9164-6a8a2876a115, pattern=[METRICS]
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:103.84|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:0b78b46b-3997-4c89-9164-6a8a2876a115,timestamp:1746446897
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 0b78b46b-3997-4c89-9164-6a8a2876a115
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 0b78b46b-3997-4c89-9164-6a8a2876a115
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:55052 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 107
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:105612.25|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:55.25|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,692 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 55250, Backend time ns: 105735000
2025-05-05T20:08:17,692 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 55250, Backend time ns: 105735000
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 106
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 106
2025-05-05T20:08:17,692 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746446897
2025-05-05T20:09:16,037 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,037 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.08075332641602|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,037 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,038 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5119.25|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7286.75|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:09:16,038 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:79.2|#Level:Host|#hostname:bohan.local,timestamp:1746446956
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.0733757019043|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5389.390625|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7516.953125|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:16,025 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:78.1|#Level:Host|#hostname:bohan.local,timestamp:1746447016
2025-05-05T20:10:27,693 [INFO ] nioEventLoopGroup-3-9 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447027
2025-05-05T20:10:27,693 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447027693
2025-05-05T20:10:27,693 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447027693
2025-05-05T20:10:27,693 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447027693
2025-05-05T20:10:27,693 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447027693
2025-05-05T20:10:27,695 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746447027
2025-05-05T20:10:28,784 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1089.38|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,c96be2fb-fcca-4575-af95-92b313f9542c, pattern=[METRICS]
2025-05-05T20:10:28,785 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId c96be2fb-fcca-4575-af95-92b313f9542c
2025-05-05T20:10:28,785 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId c96be2fb-fcca-4575-af95-92b313f9542c
2025-05-05T20:10:28,784 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:1089.38|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,c96be2fb-fcca-4575-af95-92b313f9542c, pattern=[METRICS]
2025-05-05T20:10:28,785 [INFO ] W-9011-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:55956 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 1093
2025-05-05T20:10:28,785 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,785 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:1089.38|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:c96be2fb-fcca-4575-af95-92b313f9542c,timestamp:1746447028
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1089.54|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,c96be2fb-fcca-4575-af95-92b313f9542c, pattern=[METRICS]
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:1089.54|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,c96be2fb-fcca-4575-af95-92b313f9542c, pattern=[METRICS]
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:1091752.792|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:1089.54|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:c96be2fb-fcca-4575-af95-92b313f9542c,timestamp:1746447028
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:113.625|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,786 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 113625, Backend time ns: 1092716625
2025-05-05T20:10:28,786 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 113625, Backend time ns: 1092716625
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1092
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 1092
2025-05-05T20:10:28,786 [INFO ] W-9011-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,800 [INFO ] nioEventLoopGroup-3-10 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,800 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447028800
2025-05-05T20:10:28,800 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447028800
2025-05-05T20:10:28,801 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447028801
2025-05-05T20:10:28,801 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447028801
2025-05-05T20:10:28,802 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:97.35|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,f06368c1-65af-4dc3-adf9-2d33e3c3ecca, pattern=[METRICS]
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:97.35|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,f06368c1-65af-4dc3-adf9-2d33e3c3ecca, pattern=[METRICS]
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:97.35|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:f06368c1-65af-4dc3-adf9-2d33e3c3ecca,timestamp:1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:97.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,f06368c1-65af-4dc3-adf9-2d33e3c3ecca, pattern=[METRICS]
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:97.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447028,f06368c1-65af-4dc3-adf9-2d33e3c3ecca, pattern=[METRICS]
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:97.59|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:f06368c1-65af-4dc3-adf9-2d33e3c3ecca,timestamp:1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId f06368c1-65af-4dc3-adf9-2d33e3c3ecca
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId f06368c1-65af-4dc3-adf9-2d33e3c3ecca
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:55967 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 100
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:99528.167|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:58.125|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,900 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 58125, Backend time ns: 99640167
2025-05-05T20:10:28,900 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 58125, Backend time ns: 99640167
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 99
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 99
2025-05-05T20:10:28,900 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447028
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:66.02942276000977|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5436.375|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7360.4375|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:11:16,039 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:77.9|#Level:Host|#hostname:bohan.local,timestamp:1746447076
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:65.94079971313477|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5674.015625|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8116.125|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:12:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:76.9|#Level:Host|#hostname:bohan.local,timestamp:1746447136
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:65.93860626220703|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5600.890625|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8416.4375|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:13:16,030 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:77.2|#Level:Host|#hostname:bohan.local,timestamp:1746447196
2025-05-05T20:14:11,837 [INFO ] nioEventLoopGroup-3-11 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447251
2025-05-05T20:14:11,838 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447251838
2025-05-05T20:14:11,838 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447251838
2025-05-05T20:14:11,838 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447251838
2025-05-05T20:14:11,838 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447251838
2025-05-05T20:14:11,839 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_LOG - Backend received inference at: 1746447251
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:987.35|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,3afb2e62-cdd8-44ee-bba1-6d49541d8b65, pattern=[METRICS]
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:987.35|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,3afb2e62-cdd8-44ee-bba1-6d49541d8b65, pattern=[METRICS]
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 3afb2e62-cdd8-44ee-bba1-6d49541d8b65
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 3afb2e62-cdd8-44ee-bba1-6d49541d8b65
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - HandlerTime.ms:987.35|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:3afb2e62-cdd8-44ee-bba1-6d49541d8b65,timestamp:1746447252
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:987.52|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,3afb2e62-cdd8-44ee-bba1-6d49541d8b65, pattern=[METRICS]
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:987.52|#ModelName:drawn_humanoid_detector,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,3afb2e62-cdd8-44ee-bba1-6d49541d8b65, pattern=[METRICS]
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:57413 "POST /predictions/drawn_humanoid_detector HTTP/1.1" 200 991
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout MODEL_METRICS - PredictionTime.ms:987.52|#ModelName:drawn_humanoid_detector,Level:Model|#hostname:bohan.local,requestID:3afb2e62-cdd8-44ee-bba1-6d49541d8b65,timestamp:1746447252
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:989323.208|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:65.333|#model_name:drawn_humanoid_detector,model_version:default|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,827 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 65333, Backend time ns: 989597583
2025-05-05T20:14:12,827 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 65333, Backend time ns: 989597583
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 989
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 989
2025-05-05T20:14:12,827 [INFO ] W-9008-drawn_humanoid_detector_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,853 [INFO ] nioEventLoopGroup-3-12 TS_METRICS - ts_inference_requests_total.Count:1.0|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,853 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447252853
2025-05-05T20:14:12,853 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Flushing req.cmd PREDICT repeats 1 to backend at: 1746447252853
2025-05-05T20:14:12,853 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447252853
2025-05-05T20:14:12,853 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Looping backend response at: 1746447252853
2025-05-05T20:14:12,854 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_LOG - Backend received inference at: 1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:102.96|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,864721ae-b220-4973-98a0-00318107965b, pattern=[METRICS]
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]HandlerTime.Milliseconds:102.96|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,864721ae-b220-4973-98a0-00318107965b, pattern=[METRICS]
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - HandlerTime.ms:102.96|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:864721ae-b220-4973-98a0-00318107965b,timestamp:1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.15|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,864721ae-b220-4973-98a0-00318107965b, pattern=[METRICS]
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - result=[METRICS]PredictionTime.Milliseconds:103.15|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#type:GAUGE|#hostname:bohan.local,1746447252,864721ae-b220-4973-98a0-00318107965b, pattern=[METRICS]
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout MODEL_METRICS - PredictionTime.ms:103.15|#ModelName:drawn_humanoid_pose_estimator,Level:Model|#hostname:bohan.local,requestID:864721ae-b220-4973-98a0-00318107965b,timestamp:1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 864721ae-b220-4973-98a0-00318107965b
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.BatchAggregator - Sending response for jobId 864721ae-b220-4973-98a0-00318107965b
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 ACCESS_LOG - /[0:0:0:0:0:0:0:1]:57420 "POST /predictions/drawn_humanoid_pose_estimator HTTP/1.1" 200 106
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - Requests2XX.Count:1.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_inference_latency_microseconds.Microseconds:105100.917|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - ts_queue_latency_microseconds.Microseconds:92.875|#model_name:drawn_humanoid_pose_estimator,model_version:default|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,958 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 92875, Backend time ns: 105166917
2025-05-05T20:14:12,958 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.job.RestJob - Waiting time ns: 92875, Backend time ns: 105166917
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - QueueTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 105
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend response time: 105
2025-05-05T20:14:12,958 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0 TS_METRICS - WorkerThreadTime.Milliseconds:0.0|#Level:Host|#hostname:192.168.31.54,timestamp:1746447252
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:65.94365692138672|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5801.71875|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8351.890625|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:14:16,044 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:76.4|#Level:Host|#hostname:bohan.local,timestamp:1746447256
2025-05-05T20:15:16,032 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:65.85897827148438|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.4|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5745.3125|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:7919.21875|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:15:16,033 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:76.6|#Level:Host|#hostname:bohan.local,timestamp:1746447316
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - CPUUtilization.Percent:0.0|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - DiskAvailable.Gigabytes:65.8012809753418|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - DiskUsage.Gigabytes:14.891876220703125|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - DiskUtilization.Percent:18.5|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - MemoryAvailable.Megabytes:5727.0|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUsed.Megabytes:8070.046875|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:16,007 [INFO ] pool-3-thread-2 TS_METRICS - MemoryUtilization.Percent:76.7|#Level:Host|#hostname:bohan.local,timestamp:1746447376
2025-05-05T20:16:35,738 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,778 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,806 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,738 [INFO ] W-9008-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,817 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,817 [INFO ] nioEventLoopGroup-5-12 org.pytorch.serve.wlm.WorkerThread - 9008 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,738 [INFO ] W-9008-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,828 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,830 [INFO ] W-9009-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,806 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,738 [INFO ] W-9008-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9008-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,778 [INFO ] W-9006-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9006-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,850 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,850 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,850 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,850 [INFO ] nioEventLoopGroup-5-15 org.pytorch.serve.wlm.WorkerThread - 9015 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,850 [INFO ] W-9015-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,850 [INFO ] W-9015-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,850 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,850 [INFO ] W-9015-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9015-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] W-9009-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-9 org.pytorch.serve.wlm.WorkerThread - 9009 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-2 org.pytorch.serve.wlm.WorkerThread - 9005 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,851 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] W-9010-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,851 [INFO ] W-9005-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9005-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,851 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-5 org.pytorch.serve.wlm.WorkerThread - 9002 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] W-9010-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,852 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,828 [INFO ] nioEventLoopGroup-5-6 org.pytorch.serve.wlm.WorkerThread - 9006 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [INFO ] W-9011-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,852 [INFO ] nioEventLoopGroup-5-10 org.pytorch.serve.wlm.WorkerThread - 9011 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [INFO ] W-9011-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,852 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,852 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [INFO ] W-9011-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9011-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,852 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,830 [INFO ] W-9009-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9009-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,851 [INFO ] W-9010-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9010-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,852 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,852 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,853 [INFO ] W-9014-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,853 [INFO ] W-9014-drawn_humanoid_detector_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-drawn_humanoid_detector_1.0-stdout
2025-05-05T20:16:35,853 [INFO ] W-9014-drawn_humanoid_detector_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9014-drawn_humanoid_detector_1.0-stderr
2025-05-05T20:16:35,853 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] nioEventLoopGroup-5-14 org.pytorch.serve.wlm.WorkerThread - 9014 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] nioEventLoopGroup-5-13 org.pytorch.serve.wlm.WorkerThread - 9010 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,853 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,853 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,853 [INFO ] W-9003-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9003-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,853 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] nioEventLoopGroup-5-3 org.pytorch.serve.wlm.WorkerThread - 9003 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,851 [INFO ] W-9002-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9002-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,853 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,853 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,853 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stderr org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-drawn_humanoid_pose_estimator_1.0-stderr
2025-05-05T20:16:35,854 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,854 [INFO ] nioEventLoopGroup-5-4 org.pytorch.serve.wlm.WorkerThread - 9001 Worker disconnected. WORKER_MODEL_LOADED
2025-05-05T20:16:35,854 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,854 [INFO ] W-9001-drawn_humanoid_pose_estimator_1.0-stdout org.pytorch.serve.wlm.WorkerLifeCycle - Stopped Scanner - W-9001-drawn_humanoid_pose_estimator_1.0-stdout
2025-05-05T20:16:35,854 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,854 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,854 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,854 [DEBUG] W-9003-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - System state is : WORKER_MODEL_LOADED
2025-05-05T20:16:35,851 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,851 [DEBUG] W-9015-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1765) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:482) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9014-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer$ConditionObject.awaitNanos(AbstractQueuedSynchronizer.java:1765) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.pollFirst(LinkedBlockingDeque.java:515) ~[?:?]
	at java.util.concurrent.LinkedBlockingDeque.poll(LinkedBlockingDeque.java:677) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:482) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9002-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,850 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,850 [DEBUG] W-9008-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,854 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,854 [DEBUG] W-9001-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9010-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,851 [DEBUG] W-9009-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9006-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,853 [DEBUG] W-9011-drawn_humanoid_detector_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
2025-05-05T20:16:35,852 [DEBUG] W-9005-drawn_humanoid_pose_estimator_1.0 org.pytorch.serve.wlm.WorkerThread - Backend worker monitoring thread interrupted or backend worker process died., responseTimeout:120sec
java.lang.InterruptedException: null
	at java.util.concurrent.locks.AbstractQueuedSynchronizer.acquireInterruptibly(AbstractQueuedSynchronizer.java:1011) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock$Sync.lockInterruptibly(ReentrantLock.java:161) ~[?:?]
	at java.util.concurrent.locks.ReentrantLock.lockInterruptibly(ReentrantLock.java:372) ~[?:?]
	at org.pytorch.serve.wlm.Model.pollBatch(Model.java:478) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.pollBatch(BatchAggregator.java:189) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.BatchAggregator.getRequest(BatchAggregator.java:36) ~[model-server.jar:?]
	at org.pytorch.serve.wlm.WorkerThread.run(WorkerThread.java:195) ~[model-server.jar:?]
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:572) ~[?:?]
	at java.util.concurrent.FutureTask.run(FutureTask.java:317) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1144) ~[?:?]
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:642) ~[?:?]
	at java.lang.Thread.run(Thread.java:1583) [?:?]
